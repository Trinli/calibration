"""
Tests for bootstrap ensemble of isotonic regression where the models are averaged with likelihood,
and the IR model is correct (in contrast to sklearn...).
"""

import datetime
import isotonic
import numpy as np
# from oct2py import octave
import my_ir
# from sklearn.isotonic import IsotonicRegression
# ENIR-code is R:
import rpy2.robjects as robjects
from rpy2.robjects.packages import importr
enir = importr('enir')
r = robjects.r
# Automatic conversion or numpy arrays to R-vectors
import rpy2.robjects.numpy2ri
rpy2.robjects.numpy2ri.activate()
# from sklearn.metrics import roc_auc_score
# Enable octave to find Naeini's functions!
# (download from https://github.com/pakdaman/calibration)
# octave.eval("addpath('./calibration/BBQ/')", verbose=False)

# Set test parameters:
dataset = int(input("Select dataset to run experiment on (1, 2, or 3): "))
n_iterations = int(input("Set number of iterations (30 used in paper): "))

# Load dataset:
if dataset == 1:
    # Read data for test 1:
    test_description = "test1"
    data_class = isotonic.load_pickle("./data/dataset_1_class.pickle")
    data_scores = isotonic.load_pickle("./data/dataset_1_scores.pickle")
elif dataset == 2:
    # Read data for test 2:
    test_description = "test2"
    data_class = isotonic.load_pickle("./data/dataset_2_class.pickle")
    data_scores = isotonic.load_pickle("./data/dataset_2_scores.pickle")
elif dataset == 3:
    test_description = "test3"
    data_class = isotonic.load_pickle("./data/dataset_3_class.pickle")
    data_scores = isotonic.load_pickle("./data/dataset_3_scores.pickle")
elif dataset == 4:  # Hidden experiment. Does not really provide anything interesting.
    test_description = "test4"
    data_class = np.random.binomial(1, .5, 30000)
    data_scores = np.random.uniform(low=0, high=1, size=30000)
elif dataset == 5:  # Test mode
    tmp_class = isotonic.load_pickle("./data/dataset_1_class.pickle")
    tmp_scores = isotonic.load_pickle("./data/dataset_1_scores.pickle")
    test_description = "test1"
    data_class = tmp_class[:1000]
    data_scores = tmp_scores[:1000]

else:
    print("Not a valid dataset selection.")
    import sys
    sys.exit()
print("Dataset with " + str(data_class.shape[0]) + " samples loaded.")

k = 100
print("Expected calibration error (ECE) and MCE calculated with k = " + str(k))

# Set minimum and maximum values for predictions (where applicable)
y_min = 1e-3
y_max = 1 - 1e-3

# ir_metrics = []
beir_metrics = []
# bbq_metrics = []
enir_metrics = []
# my_enir_metrics = []


def min_max(probabilities, min_y=0, max_y=1):
    res = np.array([min(1.0, max(0.0, item)) for item in probabilities])
    return res

# import imp
# imp.reload(enir_n)
smoothing = 0

for i in range(n_iterations):
    print("Iteration {0} of {1}".format(i, n_iterations))
    print(datetime.datetime.now())
    # Shuffle samples:
    # This is super important as the data is generated by a non-stationary process!
    # Data preparation includes shuffling (to randomize between multiple runs),
    # and splitting up in training- and testing sets.
    n_rows = data_scores.shape[0]
    idx = np.random.permutation(range(n_rows))
    data_class = data_class[idx]
    data_scores = data_scores[idx]
    test_class = data_class[:n_rows * 1 // 3]
    test_scores = data_scores[:n_rows * 1 // 3]
    training_class = data_class[n_rows * 1 // 3:]
    training_scores = data_scores[n_rows * 1 // 3:]

    # Create ENIR model using R:
    enir_model = enir.enir_build(robjects.FloatVector(training_scores.tolist()),
                                 robjects.BoolVector(training_class.tolist()))
    enir_prob = enir.enir_predict(enir_model, robjects.FloatVector(test_scores.tolist()))
    # Convert to numpy.array:
    enir_prob = np.array(enir_prob)
    enir_prob = min_max(enir_prob)
    enir_metrics.append(isotonic.get_metrics(test_class, enir_prob, k=k))

    # Create BEIR-model
    beir_model = my_ir.train_beir(training_class, training_scores)  # Sampling rate .95, 100 models.
    beir_prob = my_ir.predict_beir(beir_model, test_scores)
    beir_metrics.append(isotonic.get_metrics(test_class, beir_prob, k=k))
    if(max(beir_prob) > 1 + 1e-3):
        print("Max BEIR-probability: " + str(max(beir_prob)))
        break
    if(min(beir_prob) < 0):
        print("Min BEIR-probability: " + str(min(beir_prob)))
        break

print("\tMSE \t\tAUC-ROC \tECE \t\tmax(p)")
enir_tmp = isotonic.average_metrics(enir_metrics)
print("ENIR \t{0:.7} \t{1:.7} \t{2:.7} \t{3:.7}".format(enir_tmp[0], enir_tmp[1], enir_tmp[2], enir_tmp[3]))
beir_tmp = isotonic.average_metrics(beir_metrics)
print("BEIR \t{0:.7} \t{1:.7} \t{2:.7} \t{3:.7}".format(beir_tmp[0], beir_tmp[1], beir_tmp[2], beir_tmp[3]))
